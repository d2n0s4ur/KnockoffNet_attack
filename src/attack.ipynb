{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KnockoffNet Attack on CIFAR10\n",
    "# import packages\n",
    "import torch\n",
    "import timm\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# settings\n",
    "torch.manual_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "batch_size = 1000\n",
    "epochs = 100 # 1K X 100 = 100K\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50000, 10000, 60000, 10000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset loader\n",
    "data_path = '../data/'\n",
    "\n",
    "train_data_cifar10 = datasets.CIFAR10(data_path, train=True, download=True, transform=transforms.ToTensor())\n",
    "test_data_cifar10 = datasets.CIFAR10(data_path, train=False, download=True, transform=transforms.ToTensor())\n",
    "train_data_mnist = datasets.MNIST(data_path, train=True, download=True, transform=transforms.ToTensor())\n",
    "test_data_mnist = datasets.MNIST(data_path, train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "len(train_data_cifar10), len(test_data_cifar10), len(train_data_mnist), len(test_data_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49139968 0.48215841 0.44653091] [0.24703223 0.24348513 0.26158784]\n"
     ]
    }
   ],
   "source": [
    "# Normalize CIFAR10\n",
    "mean_cifar10 = train_data_cifar10.data.mean(axis=(0,1,2))/255\n",
    "std_cifar10 = train_data_cifar10.data.std(axis=(0,1,2))/255\n",
    "\n",
    "train_data_cifar10.transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean_cifar10, std_cifar10)\n",
    "])\n",
    "\n",
    "test_data_cifar10.transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean_cifar10, std_cifar10)\n",
    "])\n",
    "\n",
    "train_loader_cifar10 = torch.utils.data.DataLoader(train_data_cifar10, batch_size=batch_size, shuffle=True)\n",
    "test_loader_cifar10 = torch.utils.data.DataLoader(test_data_cifar10, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print (mean_cifar10, std_cifar10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "              ReLU-3           [-1, 64, 32, 32]               0\n",
      "          Identity-4           [-1, 64, 32, 32]               0\n",
      "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
      "          Identity-7           [-1, 64, 32, 32]               0\n",
      "              ReLU-8           [-1, 64, 32, 32]               0\n",
      "          Identity-9           [-1, 64, 32, 32]               0\n",
      "           Conv2d-10           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
      "             ReLU-12           [-1, 64, 32, 32]               0\n",
      "       BasicBlock-13           [-1, 64, 32, 32]               0\n",
      "           Conv2d-14           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-15           [-1, 64, 32, 32]             128\n",
      "         Identity-16           [-1, 64, 32, 32]               0\n",
      "             ReLU-17           [-1, 64, 32, 32]               0\n",
      "         Identity-18           [-1, 64, 32, 32]               0\n",
      "           Conv2d-19           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-20           [-1, 64, 32, 32]             128\n",
      "             ReLU-21           [-1, 64, 32, 32]               0\n",
      "       BasicBlock-22           [-1, 64, 32, 32]               0\n",
      "           Conv2d-23          [-1, 128, 16, 16]          73,728\n",
      "      BatchNorm2d-24          [-1, 128, 16, 16]             256\n",
      "         Identity-25          [-1, 128, 16, 16]               0\n",
      "             ReLU-26          [-1, 128, 16, 16]               0\n",
      "         Identity-27          [-1, 128, 16, 16]               0\n",
      "           Conv2d-28          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 16, 16]             256\n",
      "           Conv2d-30          [-1, 128, 16, 16]           8,192\n",
      "      BatchNorm2d-31          [-1, 128, 16, 16]             256\n",
      "             ReLU-32          [-1, 128, 16, 16]               0\n",
      "       BasicBlock-33          [-1, 128, 16, 16]               0\n",
      "           Conv2d-34          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-35          [-1, 128, 16, 16]             256\n",
      "         Identity-36          [-1, 128, 16, 16]               0\n",
      "             ReLU-37          [-1, 128, 16, 16]               0\n",
      "         Identity-38          [-1, 128, 16, 16]               0\n",
      "           Conv2d-39          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-40          [-1, 128, 16, 16]             256\n",
      "             ReLU-41          [-1, 128, 16, 16]               0\n",
      "       BasicBlock-42          [-1, 128, 16, 16]               0\n",
      "           Conv2d-43            [-1, 256, 8, 8]         294,912\n",
      "      BatchNorm2d-44            [-1, 256, 8, 8]             512\n",
      "         Identity-45            [-1, 256, 8, 8]               0\n",
      "             ReLU-46            [-1, 256, 8, 8]               0\n",
      "         Identity-47            [-1, 256, 8, 8]               0\n",
      "           Conv2d-48            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-49            [-1, 256, 8, 8]             512\n",
      "           Conv2d-50            [-1, 256, 8, 8]          32,768\n",
      "      BatchNorm2d-51            [-1, 256, 8, 8]             512\n",
      "             ReLU-52            [-1, 256, 8, 8]               0\n",
      "       BasicBlock-53            [-1, 256, 8, 8]               0\n",
      "           Conv2d-54            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-55            [-1, 256, 8, 8]             512\n",
      "         Identity-56            [-1, 256, 8, 8]               0\n",
      "             ReLU-57            [-1, 256, 8, 8]               0\n",
      "         Identity-58            [-1, 256, 8, 8]               0\n",
      "           Conv2d-59            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-60            [-1, 256, 8, 8]             512\n",
      "             ReLU-61            [-1, 256, 8, 8]               0\n",
      "       BasicBlock-62            [-1, 256, 8, 8]               0\n",
      "           Conv2d-63            [-1, 512, 4, 4]       1,179,648\n",
      "      BatchNorm2d-64            [-1, 512, 4, 4]           1,024\n",
      "         Identity-65            [-1, 512, 4, 4]               0\n",
      "             ReLU-66            [-1, 512, 4, 4]               0\n",
      "         Identity-67            [-1, 512, 4, 4]               0\n",
      "           Conv2d-68            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-69            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-70            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-71            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-72            [-1, 512, 4, 4]               0\n",
      "       BasicBlock-73            [-1, 512, 4, 4]               0\n",
      "           Conv2d-74            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-75            [-1, 512, 4, 4]           1,024\n",
      "         Identity-76            [-1, 512, 4, 4]               0\n",
      "             ReLU-77            [-1, 512, 4, 4]               0\n",
      "         Identity-78            [-1, 512, 4, 4]               0\n",
      "           Conv2d-79            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-80            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-81            [-1, 512, 4, 4]               0\n",
      "       BasicBlock-82            [-1, 512, 4, 4]               0\n",
      "AdaptiveAvgPool2d-83            [-1, 512, 1, 1]               0\n",
      "          Flatten-84                  [-1, 512]               0\n",
      "SelectAdaptivePool2d-85                  [-1, 512]               0\n",
      "           Linear-86                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 11,173,962\n",
      "Trainable params: 11,173,962\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 19.76\n",
      "Params size (MB): 42.63\n",
      "Estimated Total Size (MB): 62.40\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#load pretrained model(vitcim model)\n",
    "victim_model = timm.create_model(\"resnet18\", pretrained=False)\n",
    "\n",
    "# override model\n",
    "victim_model.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "victim_model.maxpool = nn.Identity()  # type: ignore\n",
    "victim_model.fc = nn.Linear(512,  10)\n",
    "\n",
    "victim_model.load_state_dict(\n",
    "            torch.hub.load_state_dict_from_url(\n",
    "                      \"https://huggingface.co/edadaltocg/resnet18_cifar10/resolve/main/pytorch_model.bin\",\n",
    "                       map_location=\"cuda\", \n",
    "                       file_name=\"resnet18_cifar10.pth\",\n",
    "             )\n",
    ")\n",
    "\n",
    "victim_model.to(device)\n",
    "summary(victim_model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
      "              ReLU-3           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
      "            Conv2d-5             [-1, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
      "              ReLU-7             [-1, 64, 8, 8]               0\n",
      "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
      "             ReLU-10             [-1, 64, 8, 8]               0\n",
      "       BasicBlock-11             [-1, 64, 8, 8]               0\n",
      "           Conv2d-12             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-13             [-1, 64, 8, 8]             128\n",
      "             ReLU-14             [-1, 64, 8, 8]               0\n",
      "           Conv2d-15             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-16             [-1, 64, 8, 8]             128\n",
      "             ReLU-17             [-1, 64, 8, 8]               0\n",
      "       BasicBlock-18             [-1, 64, 8, 8]               0\n",
      "           Conv2d-19            [-1, 128, 4, 4]          73,728\n",
      "      BatchNorm2d-20            [-1, 128, 4, 4]             256\n",
      "             ReLU-21            [-1, 128, 4, 4]               0\n",
      "           Conv2d-22            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-23            [-1, 128, 4, 4]             256\n",
      "           Conv2d-24            [-1, 128, 4, 4]           8,192\n",
      "      BatchNorm2d-25            [-1, 128, 4, 4]             256\n",
      "             ReLU-26            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-27            [-1, 128, 4, 4]               0\n",
      "           Conv2d-28            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-29            [-1, 128, 4, 4]             256\n",
      "             ReLU-30            [-1, 128, 4, 4]               0\n",
      "           Conv2d-31            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-32            [-1, 128, 4, 4]             256\n",
      "             ReLU-33            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-34            [-1, 128, 4, 4]               0\n",
      "           Conv2d-35            [-1, 256, 2, 2]         294,912\n",
      "      BatchNorm2d-36            [-1, 256, 2, 2]             512\n",
      "             ReLU-37            [-1, 256, 2, 2]               0\n",
      "           Conv2d-38            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-39            [-1, 256, 2, 2]             512\n",
      "           Conv2d-40            [-1, 256, 2, 2]          32,768\n",
      "      BatchNorm2d-41            [-1, 256, 2, 2]             512\n",
      "             ReLU-42            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-43            [-1, 256, 2, 2]               0\n",
      "           Conv2d-44            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-45            [-1, 256, 2, 2]             512\n",
      "             ReLU-46            [-1, 256, 2, 2]               0\n",
      "           Conv2d-47            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-48            [-1, 256, 2, 2]             512\n",
      "             ReLU-49            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-50            [-1, 256, 2, 2]               0\n",
      "           Conv2d-51            [-1, 512, 1, 1]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-53            [-1, 512, 1, 1]               0\n",
      "           Conv2d-54            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 1, 1]           1,024\n",
      "           Conv2d-56            [-1, 512, 1, 1]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-58            [-1, 512, 1, 1]               0\n",
      "       BasicBlock-59            [-1, 512, 1, 1]               0\n",
      "           Conv2d-60            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-62            [-1, 512, 1, 1]               0\n",
      "           Conv2d-63            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-65            [-1, 512, 1, 1]               0\n",
      "       BasicBlock-66            [-1, 512, 1, 1]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 11,181,642\n",
      "Trainable params: 11,181,642\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.29\n",
      "Params size (MB): 42.65\n",
      "Estimated Total Size (MB): 43.95\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# define attacker model\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # BatchNorm에 bias가 포함되어 있으므로, conv2d는 bias=False로 설정합니다.\n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels * BasicBlock.expansion, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * BasicBlock.expansion),\n",
    "        )\n",
    "\n",
    "        # identity mapping, input과 output의 feature map size, filter 수가 동일한 경우 사용.\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # projection mapping using 1x1conv\n",
    "        if stride != 1 or in_channels != BasicBlock.expansion * out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * BasicBlock.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.residual_function(x) + self.shortcut(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class BottleNeck(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * BottleNeck.expansion),\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels*BottleNeck.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels*BottleNeck.expansion)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.residual_function(x) + self.shortcut(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_block, num_classes=10, init_weights=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels=64\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n",
    "        self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n",
    "        self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n",
    "        self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        # weights inittialization\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self,x):\n",
    "        output = self.conv1(x)\n",
    "        output = self.conv2_x(output)\n",
    "        x = self.conv3_x(output)\n",
    "        x = self.conv4_x(x)\n",
    "        x = self.conv5_x(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    # define weight initialization function\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "def resnet18():\n",
    "    return ResNet(BasicBlock, [2,2,2,2])\n",
    "\n",
    "attacker_model = resnet18().to(device)\n",
    "\n",
    "summary(attacker_model, (3, 32, 32), device=device.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_to_victim_softmax(query):\n",
    "    \"\"\"\n",
    "    This function takes a query and returns the softmax output of the victim model.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        output = victim_model(query)\n",
    "        softmax = torch.nn.functional.softmax(output, dim=1)\n",
    "    return softmax\n",
    "\n",
    "def query_to_victim_onehot(query):\n",
    "    \"\"\"\n",
    "    This function takes a query and returns the one-hot output of the victim model.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        output = victim_model(query)\n",
    "        onehot = torch.nn.functional.one_hot(torch.argmax(output, dim=1), num_classes=10)\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax output:  tensor([[0.1055, 0.0744, 0.1003, 0.1389, 0.0987, 0.1238, 0.0945, 0.0932, 0.0902,\n",
      "         0.0804]], device='cuda:0')\n",
      "One-hot output:  tensor([[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# test query\n",
    "query = torch.rand(1, 3, 32, 32).to(device)\n",
    "softmax = query_to_victim_softmax(query)\n",
    "onehot = query_to_victim_onehot(query)\n",
    "\n",
    "print(\"Softmax output: \", softmax)\n",
    "print(\"One-hot output: \", onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Query: 10000, loss: 2.280\n",
      "query: 10000, Accuracy: 10.910 %\n",
      "Epoch: 1, Query: 20000, loss: 2.292\n",
      "query: 20000, Accuracy: 14.080 %\n",
      "Epoch: 1, Query: 30000, loss: 2.279\n",
      "query: 30000, Accuracy: 16.190 %\n",
      "Epoch: 1, Query: 40000, loss: 2.260\n",
      "query: 40000, Accuracy: 18.410 %\n",
      "Epoch: 1, Query: 50000, loss: 2.238\n",
      "query: 50000, Accuracy: 19.980 %\n",
      "Epoch: 2, Query: 60000, loss: 2.208\n",
      "query: 60000, Accuracy: 21.980 %\n",
      "Epoch: 2, Query: 70000, loss: 2.199\n",
      "query: 70000, Accuracy: 22.180 %\n",
      "Epoch: 2, Query: 80000, loss: 2.213\n",
      "query: 80000, Accuracy: 22.400 %\n",
      "Epoch: 2, Query: 90000, loss: 2.193\n",
      "query: 90000, Accuracy: 22.510 %\n",
      "Epoch: 2, Query: 100000, loss: 2.180\n",
      "query: 100000, Accuracy: 22.750 %\n",
      "Epoch: 3, Query: 110000, loss: 2.208\n",
      "query: 110000, Accuracy: 22.790 %\n",
      "Epoch: 3, Query: 120000, loss: 2.193\n",
      "query: 120000, Accuracy: 22.780 %\n",
      "Epoch: 3, Query: 130000, loss: 2.191\n",
      "query: 130000, Accuracy: 22.800 %\n",
      "Epoch: 3, Query: 140000, loss: 2.182\n",
      "query: 140000, Accuracy: 22.830 %\n",
      "Epoch: 3, Query: 150000, loss: 2.184\n",
      "query: 150000, Accuracy: 22.830 %\n",
      "Epoch: 4, Query: 160000, loss: 2.202\n",
      "query: 160000, Accuracy: 22.850 %\n",
      "Epoch: 4, Query: 170000, loss: 2.184\n",
      "query: 170000, Accuracy: 22.840 %\n",
      "Epoch: 4, Query: 180000, loss: 2.177\n",
      "query: 180000, Accuracy: 22.820 %\n",
      "Epoch: 4, Query: 190000, loss: 2.211\n",
      "query: 190000, Accuracy: 22.820 %\n",
      "Epoch: 4, Query: 200000, loss: 2.190\n",
      "query: 200000, Accuracy: 22.810 %\n",
      "Epoch: 5, Query: 210000, loss: 2.200\n",
      "query: 210000, Accuracy: 22.790 %\n",
      "Epoch: 5, Query: 220000, loss: 2.190\n",
      "query: 220000, Accuracy: 22.840 %\n",
      "Epoch: 5, Query: 230000, loss: 2.201\n",
      "query: 230000, Accuracy: 22.840 %\n",
      "Epoch: 5, Query: 240000, loss: 2.185\n",
      "query: 240000, Accuracy: 22.810 %\n",
      "Epoch: 5, Query: 250000, loss: 2.196\n",
      "query: 250000, Accuracy: 22.830 %\n",
      "Epoch: 6, Query: 260000, loss: 2.206\n",
      "query: 260000, Accuracy: 22.840 %\n",
      "Epoch: 6, Query: 270000, loss: 2.199\n",
      "query: 270000, Accuracy: 22.830 %\n",
      "Epoch: 6, Query: 280000, loss: 2.183\n",
      "query: 280000, Accuracy: 22.830 %\n",
      "Epoch: 6, Query: 290000, loss: 2.188\n",
      "query: 290000, Accuracy: 22.820 %\n",
      "Epoch: 6, Query: 300000, loss: 2.186\n",
      "query: 300000, Accuracy: 22.810 %\n",
      "Epoch: 7, Query: 310000, loss: 2.186\n",
      "query: 310000, Accuracy: 22.800 %\n",
      "Epoch: 7, Query: 320000, loss: 2.199\n",
      "query: 320000, Accuracy: 22.820 %\n",
      "Epoch: 7, Query: 330000, loss: 2.202\n",
      "query: 330000, Accuracy: 22.840 %\n",
      "Epoch: 7, Query: 340000, loss: 2.196\n",
      "query: 340000, Accuracy: 22.840 %\n"
     ]
    }
   ],
   "source": [
    "# define loss function (criterion) and optimizer\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.SGD(attacker_model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4, nesterov=True)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=3, threshold=0.001)\n",
    "\n",
    "# for plot\n",
    "plot_data = []\n",
    "\n",
    "# attack\n",
    "def knockoff_attack(data_loader, query_to_vitcim):\n",
    "    \"\"\"\n",
    "    This function performs the knockoff attack on the victim model.\n",
    "    \"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        for i, data in enumerate(data_loader):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # get victim output\n",
    "            outputs = query_to_vitcim(inputs)\n",
    "\n",
    "            # train attacker model\n",
    "            attacker_outputs = attacker_model(inputs)\n",
    "            loss = criterion(attacker_outputs, torch.argmax(outputs, dim=1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # check accuracy every 10000 queries\n",
    "            if (i + 1) % 10 == 0:\n",
    "                query_cnt = epoch * batch_size * len(data_loader) + (i + 1) * batch_size\n",
    "                print('Epoch: %d, Query: %d, loss: %.3f' % (epoch + 1, query_cnt, loss.item()))\n",
    "                lr_scheduler.step(loss.item())\n",
    "\n",
    "                # check accuracy\n",
    "                test_attacker_model(test_loader_cifar10, query_to_vitcim, query_cnt)\n",
    "\n",
    "    print('Finished Training') \n",
    "\n",
    "def test_attacker_model(data_loader, query_to_victim, query_size):\n",
    "    \"\"\"\n",
    "    This function tests the attacker model.\n",
    "    \"\"\"\n",
    "    attacker_model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data in data_loader:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = attacker_model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            # _, labels = torch.max(query_to_victim(inputs), 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('query: %d, Accuracy: %.3f %%' % (query_size, 100 * correct / total))\n",
    "        plot_data.append([query_size, 100 * correct / total])\n",
    "\n",
    "knockoff_attack(train_loader_cifar10, query_to_victim_softmax)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
